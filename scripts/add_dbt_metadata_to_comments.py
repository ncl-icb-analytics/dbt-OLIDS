#!/usr/bin/env python3
"""
Script to append DBT metadata to existing table comments in intermediate and mart models.

This script finds all SQL files in models/intermediate and models/marts directories,
locates existing post_hook comments, and appends DBT metadata for front-end visibility.
"""

import os
import re
import glob
from pathlib import Path

def find_sql_files():
    """Find all SQL files in intermediate and marts directories."""
    base_path = Path(__file__).parent.parent
    patterns = [
        str(base_path / "models/intermediate/**/*.sql"),
        str(base_path / "models/marts/**/*.sql")
    ]
    
    files = []
    for pattern in patterns:
        files.extend(glob.glob(pattern, recursive=True))
    
    return sorted(files)

def append_dbt_metadata_to_comment(file_path):
    """
    Append DBT metadata to existing post_hook comments in a SQL file.
    
    Args:
        file_path (str): Path to the SQL file to process
        
    Returns:
        bool: True if file was modified, False otherwise
    """
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # Pattern to match post_hook comments
        # This matches: post_hook=[ "COMMENT ON TABLE {{ this }} IS 'existing comment'" ]
        pattern = r'(post_hook=\s*\[\s*"COMMENT ON TABLE \{\{ this \}\} IS \')(.*?)(\'"\s*\])'
        
        def replace_comment(match):
            prefix = match.group(1)
            existing_comment = match.group(2)
            suffix = match.group(3)
            
            # Check if DBT metadata is already present
            if '🤖 Generated by dbt' in existing_comment:
                return match.group(0)  # No change needed
            
            # Append DBT metadata (using static text to avoid Jinja conflicts)
            dbt_metadata = (
                "\n\n🤖 Generated by dbt. "
                "This table is managed by dbt - for model definitions and documentation, "
                "see https://github.com/ncl-icb-analytics/dbt-olids"
            )
            
            new_comment = existing_comment + dbt_metadata
            return prefix + new_comment + suffix
        
        # Apply the replacement
        new_content = re.sub(pattern, replace_comment, content, flags=re.DOTALL)
        
        # Check if content was modified
        if new_content != content:
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(new_content)
            return True
        
        return False
        
    except Exception as e:
        print(f"Error processing {file_path}: {e}")
        return False

def main():
    """Main function to process all SQL files."""
    print("🔍 Finding SQL files in intermediate and marts directories...")
    sql_files = find_sql_files()
    print(f"Found {len(sql_files)} SQL files to process")
    
    modified_count = 0
    skipped_count = 0
    
    for file_path in sql_files:
        relative_path = os.path.relpath(file_path)
        print(f"Processing {relative_path}...", end=" ")
        
        if append_dbt_metadata_to_comment(file_path):
            print("✅ Modified")
            modified_count += 1
        else:
            print("⏭️  Skipped (no changes needed)")
            skipped_count += 1
    
    print(f"\n📊 Summary:")
    print(f"   Modified: {modified_count} files")
    print(f"   Skipped:  {skipped_count} files")
    print(f"   Total:    {len(sql_files)} files")
    
    if modified_count > 0:
        print(f"\n✨ Successfully appended DBT metadata to {modified_count} model comments!")
        print("💡 Next steps:")
        print("   1. Review the changes with 'git diff'")
        print("   2. Test a few models to ensure comments display correctly")
        print("   3. Commit the changes when satisfied")
    else:
        print("\n🎉 All files already have DBT metadata - no changes needed!")

if __name__ == "__main__":
    main()